{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'train_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0ae50c83a2b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrain_test\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'train_test'"
     ]
    }
   ],
   "source": [
    "from train_test import train, test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pylab as pl\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import shap\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_to_accu(model, X, y):\n",
    "    model.eval()\n",
    "    prob = model(X).cpu().detach().numpy()\n",
    "    pred = (prob >= 0.5).astype(int)\n",
    "    nb_errors = 0\n",
    "    for b in range(0, X.size(0)):\n",
    "        if pred[b] != y[b]:\n",
    "            nb_errors = nb_errors + 1\n",
    "    accuracy = 100 * (1 - nb_errors / X.size(0))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_bad_pred(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    prob = model(X_test).detach().numpy()\n",
    "    pred = (prob >= 0.5).astype(int)\n",
    "    return (pred == y_test.detach().numpy()).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_fracdiff(x, d):\n",
    "\n",
    "    T = len(x)\n",
    "    np2 = int(2 ** np.ceil(np.log2(2 * T - 1)))\n",
    "    k = np.arange(1, T)\n",
    "    b = (1,) + tuple(np.cumprod((k - d - 1) / k))\n",
    "    z = (0,) * (np2 - T)\n",
    "    z1 = b + z\n",
    "    z2 = tuple(x) + z\n",
    "    dx = pl.ifft(pl.fft(z1) * pl.fft(z2))\n",
    "    return np.real(dx[0:T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = sns.color_palette('RdYlGn', 10)[0]\n",
    "green = sns.color_palette('RdYlGn', 10)[-1]\n",
    "pal = [red, green]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data/data.xlsx', index_col=0, skiprows=[0, 1, 2, 3, 4, 5, 6, 8], sheet_name='features').fillna(method='ffill').shift(1).iloc[1:]\n",
    "data = data.astype(float)\n",
    "\n",
    "data['MATERIALS'] *= data['EURCHF']\n",
    "data['CONSUMER STAPLE'] *= data['EURCHF']\n",
    "data['INDUSTRIALS'] *= data['EURCHF']\n",
    "data['CONSUMER DIS.'] *= data['EURCHF']\n",
    "data['HEALTH CARE'] *= data['EURCHF']\n",
    "data['FINANCIALS'] *= data['EURCHF']\n",
    "\n",
    "data['GOLD'] *= data['USDCHF']\n",
    "data['SILVER'] *= data['USDCHF']\n",
    "data['BRENT'] *= data['USDCHF']\n",
    "data['SP500'] *= data['USDCHF']\n",
    "data['RUSSELL 2000'] *= data['USDCHF']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prices = data[['SMALL_MID', 'LARGE']]\n",
    "target_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_price = data['SPI']\n",
    "raw_features = data[data.columns.difference(['SPI', 'EURCHF', 'USDCHF'])]\n",
    "raw_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "return_corr_matrix = raw_features.pct_change().corr()\n",
    "return_corr_matrix[return_corr_matrix > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_features = raw_features.drop(columns=['US 5YEAR', 'RUSSELL 2000', 'INDUSTRIALS', 'SILVER'])\n",
    "raw_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "technical_features = raw_features[raw_features.columns.difference(['SURPRISE'])]\n",
    "\n",
    "mom5 = technical_features.rolling(5).apply(lambda x: np.log(x[-1] / x[0]) / len(x))\n",
    "mom5 = mom5.add_suffix(' mom5')\n",
    "\n",
    "mom21 = technical_features.rolling(21).apply(lambda x: np.log(x[-1] / x[0]) / len(x))\n",
    "mom21 = mom21.add_suffix(' mom21')\n",
    "\n",
    "mom63 = technical_features.rolling(63).apply(lambda x: np.log(x[-1] / x[0]) / len(x))\n",
    "mom63 = mom63.add_suffix(' mom63')\n",
    "\n",
    "ema_12 = technical_features.ewm(span=12).mean()\n",
    "ema_26 = technical_features.ewm(span=26).mean()\n",
    "MACD = (ema_12 - ema_26) - (ema_12 - ema_26).ewm(span=9).mean()\n",
    "MACD = MACD.add_suffix(' MACD')\n",
    "\n",
    "# raw_features['SURPRISE'] = fast_fracdiff(raw_features['SURPRISE'], 0.5)\n",
    "\n",
    "features = pd.concat([mom5, mom21, mom63, MACD, raw_features['SURPRISE']], axis=1).ewm(5).mean().dropna()\n",
    "features.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop(columns=['FINANCIALS mom5', 'GOLD mom5', 'HEALTH CARE mom5',  'MATERIALS mom5',  \n",
    "                                  'SMALL_MID mom5',  'US 10YEAR mom5',  'CONSUMER STAPLE mom21',  \n",
    "                                  'GOLD mom21',  'SMALL_MID mom21',  'US 10YEAR mom21',  'US 2YEAR mom21',  \n",
    "                                  'CONSUMER STAPLE mom63',  'FINANCIALS mom63',  'HEALTH CARE mom63',  \n",
    "                                  'LARGE mom63',  'SMALL_MID mom63',  'US 10YEAR mom63', \n",
    "                                  'US 2YEAR mom63',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop(columns=['CONSUMER STAPLE mom5', 'LARGE mom5', 'CONSUMER DIS. mom21',  \n",
    "                                  'BRENT mom63', 'GOLD mom63',  'MATERIALS mom63',  \n",
    "                                  'CONSUMER DIS. MACD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr_matrix = features.corr()\n",
    "corr_matrix[corr_matrix > 0.85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_window = 4\n",
    "\n",
    "last_date_train = target_prices.index[-1]\n",
    "\n",
    "forward_weekly_returns = target_prices.rolling(5).apply(lambda x: np.log(x[-1] / x[0]) / len(x)).shift(-5)\n",
    "forward_weekly_returns['abs_diff'] = np.abs(forward_weekly_returns.SMALL_MID - forward_weekly_returns.LARGE)\n",
    "\n",
    "best_pred = (forward_weekly_returns.SMALL_MID > forward_weekly_returns.LARGE).astype(int)\n",
    "best_pred = best_pred[forward_weekly_returns.abs_diff > 0.0005]\n",
    "\n",
    "start_date = last_date_train - relativedelta(years=training_window)\n",
    "\n",
    "df_output = best_pred.loc[start_date:last_date_train]\n",
    "df_input = features.reindex(df_output.index)\n",
    "\n",
    "X = df_input.values\n",
    "y = df_output.values\n",
    "\n",
    "index = df_input.index\n",
    "\n",
    "X, y = torch.from_numpy(X).float(), torch.from_numpy(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y.numpy(), test_size= 0.2, shuffle=False)\n",
    "print('Number of train sample :', len(X_train))\n",
    "print('Number of test sample :', len(X_test))\n",
    "\n",
    "class_count_train = np.unique(y_train, axis=0, return_counts=True)[1]\n",
    "class_count_test = np.unique(y_test, axis=0, return_counts=True)[1]\n",
    "weights_train = class_count_train / sum(class_count_train)\n",
    "weights_test = class_count_test / sum(class_count_test)\n",
    "print('Allocation of best returns in train set :', weights_train)\n",
    "print('Allocation of best returns in test set :', weights_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logit_model = LogisticRegression(max_iter=1000, penalty = 'l2', solver='sag', tol=1e-7)\n",
    "logit_model.fit(X_train, y_train)\n",
    "y_hat = logit_model.predict(X_test)\n",
    "y_hat_prob = logit_model.predict_proba(X_test)\n",
    "\n",
    "y_hat_logit_train = logit_model.predict(X_train)\n",
    "y_hat_logit_test = logit_model.predict(X_test)\n",
    "\n",
    "print('Accuracy on train set', round(100 * accuracy_score(y_hat_logit_train, y_train), 2), '%')\n",
    "print('Accuracy on test set', round(100 * accuracy_score(y_hat_logit_test, y_test), 2), '%')\n",
    "\n",
    "class_count_train = np.unique(y_hat_logit_train, axis=0, return_counts=True)[1]\n",
    "class_count_test = np.unique(y_hat_logit_test, axis=0, return_counts=True)[1]\n",
    "weights_train = class_count_train / sum(class_count_train)\n",
    "weights_test = class_count_test / sum(class_count_test)\n",
    "print('Rate of small predictions in train set :', round(weights_train[0], 4) * 100, '%')\n",
    "print('Rate of small predictions in test set :', round(weights_test[0], 4) * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "betas = logit_model.coef_.reshape(-1)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 20))\n",
    "sns.barplot(y=features.columns, x=np.divide(betas, std), color='r')\n",
    "ax.tick_params(labelsize=6, length=0)\n",
    "plt.title('Global Feature importance for a Logistic Regression model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y.numpy(), test_size= 0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(criterion='gini', max_depth=None, min_samples_leaf=10, \n",
    "                             min_samples_split=10, n_estimators= 1000)\n",
    "\n",
    "rfc = rfc.fit(X_train, y_train)\n",
    "y_hat_rfc_train = rfc.predict(X_train)\n",
    "y_hat_rfc_test = rfc.predict(X_test)\n",
    "\n",
    "print('Accuracy on train set', round(100 * accuracy_score(y_hat_rfc_train, y_train), 2), '%')\n",
    "print('Accuracy on test set', round(100 * accuracy_score(y_hat_rfc_test, y_test), 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "importances = rfc.feature_importances_\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 15))\n",
    "sns.barplot(y=features.columns, x=importances, color='r')\n",
    "ax.tick_params(labelsize=8, length=0)\n",
    "plt.tight_layout()\n",
    "plt.title('Global Feature importance for a Random Forest model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(rfc)\n",
    "shap_values_train = np.mean(explainer.shap_values(X_test), axis=0)\n",
    "shap_values_test = np.mean(explainer.shap_values(X_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shap_values_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-689ada4c98ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshap_values_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'shap_values_train' is not defined"
     ]
    }
   ],
   "source": [
    "shap_values_train.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 20), sharey=True)\n",
    "\n",
    "sns.barplot(ax=axs[0], x=shap_values_train.mean(axis=0), y=features.columns, color='r')\n",
    "axs[0].tick_params(length=0)\n",
    "axs[0].set_title('Train set')\n",
    "\n",
    "sns.barplot(ax=axs[1], x=shap_values_test.mean(axis=0), y=features.columns, color='r')\n",
    "axs[1].tick_params(length=0)\n",
    "axs[1].set_title('Test set')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(rfc)\n",
    "shap_values = shap_values_train\n",
    "\n",
    "fig, axs = plt.subplots(math.ceil(len(features.columns) / 4), 4, figsize=(8.27, 11.69), sharex=False, sharey=True)\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, feature in enumerate(features.columns):\n",
    "    sns.scatterplot(ax=axs[i], x=X_train[:, i], y=shap_values[:, i], s=2)\n",
    "    axs[i].axhline(y=0., linestyle='--', color='r', lw=0.25)\n",
    "    axs[i].tick_params(axis='both', length=0, labelbottom=False, labelleft=False)\n",
    "    axs[i].set_title(feature, fontsize=3, pad=2)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.15, hspace=0.15)\n",
    "    \n",
    "plt.savefig('plots/RF_features_importances_train.png', dpi=300, facecolor='white', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_bad_pred_rf(model, X_test, y_test):\n",
    "    pred = model.predict(X_test)\n",
    "    return (pred == y_test).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shap_values = shap_values_test\n",
    "good_bad = good_bad_pred_rf(rfc, X_test, y_test)\n",
    "\n",
    "red = sns.color_palette('RdYlGn', 10)[0]\n",
    "green = sns.color_palette('RdYlGn', 10)[-1]\n",
    "pal = [green, red]\n",
    "\n",
    "fig, axs = plt.subplots(math.ceil(len(features.columns) / 8), 8, figsize=(8.27, 11.69), sharex=False, sharey=True)\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, feature in enumerate(features.columns):\n",
    "    df = pd.DataFrame()\n",
    "    df['value'] = X_test[:, i]\n",
    "    df['IG'] = shap_values[:, i]\n",
    "    df['GOOD_BAD'] = good_bad\n",
    "    df.GOOD_BAD = df.GOOD_BAD.replace({1:'GOOD', 0:'BAD'})\n",
    "    \n",
    "    sns.scatterplot(ax=axs[i], data=df, x='value', y='IG', hue='GOOD_BAD', s=2, legend=False, palette=pal)\n",
    "\n",
    "    axs[i].axhline(y=0., linestyle='--', color='r', lw=0.25)\n",
    "    axs[i].tick_params(axis='both', length=0, labelbottom=False, labelleft=False)\n",
    "    axs[i].set_xlabel(None)\n",
    "    axs[i].set_ylabel(None)\n",
    "    \n",
    "    axs[i].set_title(feature, fontsize=3, pad=2)\n",
    "\n",
    "# fig.delaxes(axs[-3])\n",
    "# fig.delaxes(axs[-2])\n",
    "# fig.delaxes(axs[-1])\n",
    "\n",
    "plt.subplots_adjust(wspace=0.15, hspace=0.15)\n",
    "plt.savefig('plots/RF_features_importances_test.png', dpi=300, facecolor='white', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, test_indices, _, _ = train_test_split(range(len(y)), y, test_size=0.2, shuffle=False)\n",
    "X_train, y_train, X_test, y_test = X[train_indices], y[train_indices], X[test_indices], y[test_indices]\n",
    "\n",
    "X_mean = X_train.mean(dim=[0], keepdim=True)\n",
    "X_std = X_train.std(dim=[0], keepdim=True)\n",
    "X_train = X_train.sub_(X_mean).div_(X_std)\n",
    "X_test = X_test.sub_(X_mean).div_(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train period :', index[train_indices][0].date(), 'to', index[train_indices][-1].date())\n",
    "print('Test period :', index[test_indices][0].date(), 'to', index[test_indices][-1].date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP1(nn.Module):\n",
    "    def __init__(self, nbr_features, pdrop=0.1, hidden_size=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(nbr_features, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.drop1 = nn.Dropout(pdrop)\n",
    "        self.drop2 = nn.Dropout(pdrop)\n",
    "        self.drop3 = nn.Dropout(pdrop)\n",
    "        \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.relu1(self.bn1(self.drop1(self.fc1(x))))\n",
    "        x = self.relu2(self.bn2(self.drop2(self.fc2(x))))\n",
    "        x = self.relu3(self.drop3(self.fc3(x)))\n",
    "        x = self.sigmoid(self.fc4(x))       \n",
    "\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP2(nn.Module):\n",
    "    def __init__(self, nbr_features, pdrop=0.1, hidden_size=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(nbr_features, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.drop1 = nn.Dropout(pdrop)\n",
    "        self.drop2 = nn.Dropout(pdrop)\n",
    "        self.drop3 = nn.Dropout(pdrop)\n",
    "        \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.relu1(self.bn1(self.drop1(self.fc1(x))))\n",
    "        x = self.relu2(self.bn2(self.drop2(self.fc2(x))))\n",
    "        x = self.relu3(self.drop3(self.fc3(x)))\n",
    "        x = self.sigmoid(self.fc4(x))       \n",
    "\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP3(nn.Module):\n",
    "    def __init__(self, nbr_features, pdrop=0.1, hidden_size=50):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(nbr_features, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.drop1 = nn.Dropout(pdrop)\n",
    "        self.drop2 = nn.Dropout(pdrop)\n",
    "        self.drop3 = nn.Dropout(pdrop)\n",
    "        \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.relu1(self.bn1(self.drop1(self.fc1(x))))\n",
    "        x = self.relu2(self.bn2(self.drop2(self.fc2(x))))\n",
    "        x = self.relu3(self.drop3(self.fc3(x)))\n",
    "        x = self.sigmoid(self.fc4(x))       \n",
    "\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 1e-3\n",
    "weight_decay = 1e-4\n",
    "dropout = 0.2\n",
    "batch_size = 20\n",
    "nb_epochs = 100\n",
    "\n",
    "verbose = 3\n",
    "\n",
    "nbr_features = X.size(1)\n",
    "\n",
    "model_MLP1 = MLP1(nbr_features, pdrop=dropout)\n",
    "model_MLP2 = MLP2(nbr_features, pdrop=dropout)\n",
    "model_MLP3 = MLP3(nbr_features, pdrop=dropout)\n",
    "\n",
    "train(model_MLP1, X_train, y_train, nb_epochs=nb_epochs, X_test=X_test, y_test=y_test, \n",
    "      batch_size=batch_size, eta=eta, weight_decay=weight_decay, verbose=verbose)\n",
    "\n",
    "train(model_MLP2, X_train, y_train, nb_epochs=nb_epochs, X_test=X_test, y_test=y_test, \n",
    "      batch_size=batch_size, eta=eta, weight_decay=weight_decay, verbose=verbose)\n",
    "\n",
    "train(model_MLP3, X_train, y_train, nb_epochs=nb_epochs, X_test=X_test, y_test=y_test, \n",
    "      batch_size=batch_size, eta=eta, weight_decay=weight_decay, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_MLP1.eval()\n",
    "print(f' MLP Accuracy on train set : {output_to_accu(model_MLP1, X_train, y_train):.2f} %')\n",
    "print(f' MLP Accuracy on test set : {output_to_accu(model_MLP1, X_test, y_test):.2f} %')\n",
    "\n",
    "model_MLP2.eval()\n",
    "print(f' MLP Accuracy on train set : {output_to_accu(model_MLP2, X_train, y_train):.2f} %')\n",
    "print(f' MLP Accuracy on test set : {output_to_accu(model_MLP2, X_test, y_test):.2f} %')\n",
    "\n",
    "model_MLP3.eval()\n",
    "print(f' MLP Accuracy on train set : {output_to_accu(model_MLP3, X_train, y_train):.2f} %')\n",
    "print(f' MLP Accuracy on test set : {output_to_accu(model_MLP3, X_test, y_test):.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IG_barplot(model_list, X_test):  \n",
    "    \n",
    "    fig, axs = plt.subplots(1, len(model_list), figsize=(20,30), sharex=True, sharey=True)\n",
    "    axs = axs.ravel()\n",
    "    for i, model in enumerate(model_list):\n",
    "        model.eval()\n",
    "        ig = IntegratedGradients(model)\n",
    "        attr = np.abs(ig.attribute(X_test, return_convergence_delta=False).detach().numpy())\n",
    "        std = np.std(attr, axis=0)\n",
    "        \n",
    "        attr_matrix = np.mean(np.abs(attr), axis=0)\n",
    "\n",
    "        sns.barplot(ax=axs[i], y=features.columns, x=attr_matrix, yerr=std, color='r', orient='h')\n",
    "        axs[i].tick_params(length=0)\n",
    "        axs[i].set_title(model.__class__.__name__)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_list = [model_MLP1, model_MLP2, model_MLP3]\n",
    "IG_barplot(model_list, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = IntegratedGradients(model_MLP1)\n",
    "attributes_train = ig.attribute(X_train, return_convergence_delta=False).detach().numpy()\n",
    "attributes_test = ig.attribute(X_test, return_convergence_delta=False).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 15), sharey=True)\n",
    "\n",
    "attr_train = np.mean(np.abs(attributes_train), axis=0)\n",
    "attr_test = np.mean(np.abs(attributes_test), axis=0)\n",
    "\n",
    "sns.barplot(ax=axs[0], x=attr_train, y=features.columns, color='r')\n",
    "axs[0].tick_params(length=0, labelsize=8)\n",
    "axs[0].set_title('Train set')\n",
    "\n",
    "sns.barplot(ax=axs[1], x=attr_test, y=features.columns, color='r')\n",
    "axs[1].tick_params(length=0)\n",
    "axs[1].set_title('Test set')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "good_bad = good_bad_pred(model_MLP1, X_train, y_train)\n",
    "\n",
    "fig, axs = plt.subplots(math.ceil(len(features.columns) / 4), 4, figsize=(8.27, 11.69), sharex=False, sharey=True)\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, feature in enumerate(features.columns):\n",
    "    df = pd.DataFrame()\n",
    "    df['value'] = X_train[:, i]\n",
    "    df['IG'] = attributes_train[:, i]\n",
    "    df['GOOD_BAD'] = good_bad\n",
    "    df['target'] = y_train\n",
    "    df.GOOD_BAD = df.GOOD_BAD.replace({1:'Good', 0:'Bad'})\n",
    "    df.target = df.target.replace({1:'Large', 0:'Small'})\n",
    "    \n",
    "    sns.scatterplot(ax=axs[i], data=df, x='value', y='IG', hue='GOOD_BAD', style='target', s=2, \n",
    "                    palette=list(reversed(pal)), legend=False, edgecolors=None)\n",
    "    \n",
    "    axs[i].axvline(x=0., linestyle='--', color='r', lw=0.25)\n",
    "    axs[i].axhline(y=0., linestyle='--', color='r', lw=0.25)\n",
    "    axs[i].set_xlabel(None)\n",
    "    axs[i].set_ylabel(None)\n",
    "    axs[i].tick_params(axis='both', length=0, labelbottom=False, labelleft=False)\n",
    "    axs[i].set_title(feature, fontsize=3, pad=2)\n",
    "\n",
    "# fig.delaxes(axs[-3])\n",
    "# fig.delaxes(axs[-2])\n",
    "# fig.delaxes(axs[-1])\n",
    "\n",
    "plt.subplots_adjust(wspace=0.15, hspace=0.15)\n",
    "\n",
    "plt.savefig('plots/MLP_features_importances_train.png', format='png', bbox_inches='tight', dpi=500, facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "good_bad = good_bad_pred(model_MLP1, X_test, y_test)\n",
    "\n",
    "fig, axs = plt.subplots(math.ceil(len(features.columns) / 4), 4, figsize=(8.27, 11.69), sharex=False, sharey=True)\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, feature in enumerate(features.columns):\n",
    "    df = pd.DataFrame()\n",
    "    df['value'] = X_test[:, i]\n",
    "    df['IG'] = attributes_test[:, i]\n",
    "    df['GOOD_BAD'] = good_bad\n",
    "    df['target'] = y_test\n",
    "    df.GOOD_BAD = df.GOOD_BAD.replace({1:'Good', 0:'Bad'})\n",
    "    df.target = df.target.replace({1:'Large', 0:'Small'})\n",
    "    \n",
    "    sns.scatterplot(ax=axs[i], data=df, x='value', y='IG', hue='GOOD_BAD', s=2, style='target',\n",
    "                    palette=list(reversed(pal)), legend=False, edgecolors=None)\n",
    "    \n",
    "    axs[i].axvline(x=0., linestyle='--', color='r', lw=0.25)\n",
    "    axs[i].axhline(y=0., linestyle='--', color='r', lw=0.25)\n",
    "    axs[i].tick_params(axis='both', length=0, labelbottom=False, labelleft=False)\n",
    "    axs[i].set_xlabel(None)\n",
    "    axs[i].set_ylabel(None)\n",
    "    axs[i].set_title(feature, fontsize=3, pad=2)\n",
    "\n",
    "# fig.delaxes(axs[-3])\n",
    "# fig.delaxes(axs[-2])\n",
    "# fig.delaxes(axs[-1])\n",
    "\n",
    "plt.subplots_adjust(wspace=0.15, hspace=0.15)\n",
    "plt.savefig('plots/MLP_features_importances_test.png', format='png', bbox_inches='tight', dpi=500, facecolor='white')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM WITH SEQUENTIAL INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_period = 21\n",
    "\n",
    "last_date_train = target_prices.index[-1]\n",
    "\n",
    "num_features = len(features.columns)\n",
    "\n",
    "forward_weekly_returns = target_prices.rolling(5).apply(lambda x: np.log(x[-1] / x[0]) / len(x)).shift(-5)\n",
    "forward_weekly_returns['abs_diff'] = np.abs(forward_weekly_returns.SMALL_MID - forward_weekly_returns.LARGE)\n",
    "\n",
    "best_pred = (forward_weekly_returns.SMALL_MID > forward_weekly_returns.LARGE).astype(int)\n",
    "\n",
    "start_date = last_date_train - relativedelta(years=training_window)\n",
    "\n",
    "df_output = best_pred.loc[start_date:]\n",
    "final_index = list(df_output.reset_index()[forward_weekly_returns.loc[start_date:].reset_index().abs_diff > 0.0005].index)\n",
    "\n",
    "# start_date_input = target_prices.loc[:start_date].index[0]\n",
    "\n",
    "df_input = features.loc[:df_output.index[-1]]\n",
    "\n",
    "X = []\n",
    "\n",
    "for idx in df_output.index:\n",
    "\n",
    "    df_input_period = df_input.loc[:idx].iloc[-input_period:]\n",
    "    X_period = df_input_period.values.reshape(input_period, num_features)\n",
    "    X.append(X_period)\n",
    "\n",
    "X = np.array(X)\n",
    "X = X[final_index]\n",
    "y = df_output.values\n",
    "y = y[final_index]\n",
    "\n",
    "X, y = torch.from_numpy(X).float(), torch.from_numpy(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, test_indices, _, _ = train_test_split(range(len(y)), y, test_size=0.2, shuffle=False, random_state=1)\n",
    "X_train, y_train, X_test, y_test = X[train_indices], y[train_indices], X[test_indices], y[test_indices]\n",
    "print('Number of train sample', len(X_train))\n",
    "print('Number of test sample', len(X_test))\n",
    "\n",
    "X_mean = X_train.mean(dim=[0, 1], keepdim=True)\n",
    "X_std = X_train.std(dim=[0, 1], keepdim=True)\n",
    "X_train = X_train.sub_(X_mean).div_(X_std)\n",
    "X_test = X_test.sub_(X_mean).div_(X_std)\n",
    "\n",
    "class_count_train = np.unique(y_train.cpu(), axis=0, return_counts=True)[1]\n",
    "class_count_test = np.unique(y_test.cpu(), axis=0, return_counts=True)[1]\n",
    "weights_train = torch.tensor(class_count_train / sum(class_count_train))\n",
    "weights_test = torch.tensor(class_count_test / sum(class_count_test))\n",
    "print('Allocation of best returns in train set :', weights_train.cpu().numpy())\n",
    "print('Allocation of best returns in test set :', weights_test.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM1(nn.Module):\n",
    "\n",
    "    def __init__(self, nbr_features, hidden_size=10, num_layers=2, pdrop=0.1):\n",
    "        super(LSTM1, self).__init__()\n",
    "        \n",
    "        self.nbr_features = nbr_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = pdrop\n",
    "        self.device = device\n",
    "        self.lstm = nn.LSTM(input_size=self.nbr_features, hidden_size=self.hidden_size, \n",
    "                            num_layers=self.num_layers, batch_first=True, dropout=self.dropout)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), x.size(1), x.size(2))\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.sigmoid(self.fc(x[:, -1, :]))\n",
    "\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM2(nn.Module):\n",
    "\n",
    "    def __init__(self, nbr_features, hidden_size=50, num_layers=2, pdrop=0.1):\n",
    "        super(LSTM2, self).__init__()\n",
    "        \n",
    "        self.nbr_features = nbr_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = pdrop\n",
    "        self.device = device\n",
    "        self.lstm = nn.LSTM(input_size=self.nbr_features, hidden_size=self.hidden_size, \n",
    "                            num_layers=self.num_layers, batch_first=True, dropout=self.dropout)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), x.size(1), x.size(2))\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.sigmoid(self.fc(x[:, -1, :]))\n",
    "\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM3(nn.Module):\n",
    "\n",
    "    def __init__(self, nbr_features, hidden_size=100, num_layers=3, pdrop=0.1):\n",
    "        super(LSTM3, self).__init__()\n",
    "        \n",
    "        self.nbr_features = nbr_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = pdrop\n",
    "        self.device = device\n",
    "        self.lstm = nn.LSTM(input_size=self.nbr_features, hidden_size=self.hidden_size, \n",
    "                            num_layers=self.num_layers, batch_first=True, dropout=self.dropout)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # h0 = torch.randn(self.num_layers, x.size(0), self.hidden_size)\n",
    "        # c0 = torch.randn(self.num_layers, x.size(0), self.hidden_size)\n",
    "        x = x.view(x.size(0), x.size(1), x.size(2))\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.sigmoid(self.fc(x[:, -1, :]))\n",
    "\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 1e-3\n",
    "weight_decay = 1e-4\n",
    "dropout = 0.2\n",
    "batch_size = 20\n",
    "nb_epochs = 20\n",
    "\n",
    "verbose = 3\n",
    "\n",
    "nbr_features = X.size(2)\n",
    "\n",
    "model_LSTM1 = LSTM1(nbr_features, pdrop=dropout)\n",
    "model_LSTM2 = LSTM2(nbr_features, pdrop=dropout)\n",
    "model_LSTM3 = LSTM3(nbr_features, pdrop=dropout)\n",
    "\n",
    "train(model_LSTM1, X_train, y_train, nb_epochs=nb_epochs, X_test=X_test, y_test=y_test, \n",
    "      batch_size=batch_size, eta=eta, weight_decay=weight_decay, verbose=verbose)\n",
    "train(model_LSTM2, X_train, y_train, nb_epochs=nb_epochs, X_test=X_test, y_test=y_test, \n",
    "      batch_size=batch_size, eta=eta, weight_decay=weight_decay, verbose=verbose)\n",
    "train(model_LSTM3, X_train, y_train, nb_epochs=nb_epochs, X_test=X_test, y_test=y_test, \n",
    "      batch_size=batch_size, eta=eta, weight_decay=weight_decay, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LSTM1.eval()\n",
    "print(f' LSTM1 Accuracy on train set : {output_to_accu(model_LSTM1, X_train, y_train):.2f} %')\n",
    "print(f' LSTM1 Accuracy on test set : {output_to_accu(model_LSTM1, X_test, y_test):.2f} %')\n",
    "\n",
    "model_LSTM2.eval()\n",
    "print(f' LSTM2 Accuracy on train set : {output_to_accu(model_LSTM2, X_train, y_train):.2f} %')\n",
    "print(f' LSTM2 Accuracy on test set : {output_to_accu(model_LSTM2, X_test, y_test):.2f} %')\n",
    "\n",
    "model_LSTM3.eval()\n",
    "print(f' LSTM3 Accuracy on train set : {output_to_accu(model_LSTM3, X_train, y_train):.2f} %')\n",
    "print(f' LSTM3 Accuracy on test set : {output_to_accu(model_LSTM3, X_test, y_test):.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = IntegratedGradients(model_LSTM1)\n",
    "attributes_train = ig.attribute(X_train, return_convergence_delta=False).detach().numpy()\n",
    "attributes_test = ig.attribute(X_test, return_convergence_delta=False).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 15), sharey=True, sharex=True)\n",
    "\n",
    "attr_train = np.sum(np.mean(np.abs(attributes_train), axis=0), axis=0)\n",
    "attr_test = np.sum(np.mean(np.abs(attributes_test), axis=0), axis=0)\n",
    "\n",
    "sns.barplot(ax=axs[0], x=attr_train, y=features.columns, color='r')\n",
    "axs[0].tick_params(length=0, labelsize=8)\n",
    "axs[0].set_title('Train set')\n",
    "\n",
    "sns.barplot(ax=axs[1], x=attr_test, y=features.columns, color='r')\n",
    "axs[1].tick_params(length=0, labelsize=8)\n",
    "axs[1].set_title('Test set')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bad = good_bad_pred(model_LSTM1, X_train, y_train)\n",
    "\n",
    "fig, axs = plt.subplots(math.ceil(len(features.columns) / 4), 4, figsize=(8.27, 11.69), sharex=False, sharey=True)\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, feature in enumerate(features.columns):\n",
    "    df = pd.DataFrame()\n",
    "    df['value'] = X_train.mean(axis=1)[:, i]\n",
    "    df['IG'] = np.sum(attributes_train, axis=1)[:, i]\n",
    "    df['GOOD_BAD'] = good_bad\n",
    "    df['target'] = y_train\n",
    "    \n",
    "    sns.scatterplot(ax=axs[i], data=df, x='value', y='IG', hue='GOOD_BAD', style='target',\n",
    "                    s=2, legend=False, edgecolors=None, palette=list(reversed(pal)))\n",
    "    \n",
    "    axs[i].axvline(x=0., linestyle='--', color='r', lw=0.25)\n",
    "    axs[i].axhline(y=0., linestyle='--', color='r', lw=0.25)\n",
    "    axs[i].set_xlabel(None)\n",
    "    axs[i].set_ylabel(None)\n",
    "    axs[i].tick_params(axis='both', length=0, labelbottom=False, labelleft=False)\n",
    "    axs[i].set_title(feature, fontsize=3, pad=2)\n",
    "\n",
    "# fig.delaxes(axs[-3])\n",
    "# fig.delaxes(axs[-2])\n",
    "# fig.delaxes(axs[-1])\n",
    "\n",
    "plt.subplots_adjust(wspace=0.15, hspace=0.15)\n",
    "\n",
    "plt.savefig('plots/LSTM_features_importances_train.png', format='png', bbox_inches='tight', dpi=500, facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bad = good_bad_pred(model_LSTM1, X_test, y_test)\n",
    "\n",
    "fig, axs = plt.subplots(math.ceil(len(features.columns) / 4), 4, figsize=(8.27, 11.69), sharex=False, sharey=True)\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, feature in enumerate(features.columns):\n",
    "    df = pd.DataFrame()\n",
    "    df['value'] = X_test.mean(axis=1)[:, i]\n",
    "    df['IG'] = np.sum(attributes_test, axis=1)[:, i]\n",
    "    df['GOOD_BAD'] = good_bad\n",
    "    df['target'] = y_test\n",
    "    \n",
    "    sns.scatterplot(ax=axs[i], data=df, x='value', y='IG', hue='GOOD_BAD', style='target',\n",
    "                    s=2, legend=False, edgecolors=None, palette=list(reversed(pal)))\n",
    "    \n",
    "    axs[i].axvline(x=0., linestyle='--', color='r', lw=0.25)\n",
    "    axs[i].axhline(y=0., linestyle='--', color='r', lw=0.25)\n",
    "    axs[i].set_xlabel(None)\n",
    "    axs[i].set_ylabel(None)\n",
    "    axs[i].tick_params(axis='both', length=0, labelbottom=False, labelleft=False)\n",
    "    axs[i].set_title(feature, fontsize=3, pad=2)\n",
    "\n",
    "# fig.delaxes(axs[-3])\n",
    "# fig.delaxes(axs[-2])\n",
    "# fig.delaxes(axs[-1])\n",
    "\n",
    "plt.subplots_adjust(wspace=0.15, hspace=0.15)\n",
    "\n",
    "plt.savefig('plots/LSTM_features_importances_train.png', format='png', bbox_inches='tight', dpi=500, facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = np.mean(np.abs(attributes_train), axis=0).T\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,20))\n",
    "sns.heatmap(data=attr, annot=False, cmap='Reds', cbar=False, \n",
    "            yticklabels=features.columns, xticklabels=list(reversed(- (np.arange(input_period) + 1))))\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=8, labelleft=True, labeltop=True, labelbottom=False, rotation=0, length=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = np.mean(np.abs(attributes_test), axis=0).T\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,20))\n",
    "sns.heatmap(data=attr, annot=False, cmap='Reds', cbar=False, \n",
    "            yticklabels=features.columns, xticklabels=list(reversed(- (np.arange(input_period) + 1))))\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=8, labelleft=True, labeltop=True, labelbottom=False, rotation=0, length=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
