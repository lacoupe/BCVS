{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from tqdm import tqdm\n",
    "from helpers import performance_plot, resume_backtest, annual_alpha_plot, price_to_perf, last_month, next_friday, prob_to_pred, printmetrics\n",
    "from sklearn.metrics import classification_report\n",
    "from models import MLP, GRU, LSTM\n",
    "from train_test import train, test\n",
    "from data import get_data\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_strat(features, forward_weekly_returns, hidden_size=10, model_name='MLP',\n",
    "                   nb_epochs=50, training_window=5, input_period=10, dropout=0.1,\n",
    "                   batch_size=10, verbose=0, eta=1e-3, weight_decay=0, num_layers=2):\n",
    "\n",
    "    print('Backtesting model ' + model_name)\n",
    "\n",
    "    threshold_return_diff = 0.0005\n",
    "\n",
    "    nbr_features = len(features.columns)\n",
    "\n",
    "    best_pred = (forward_weekly_returns.SMALL_MID > forward_weekly_returns.LARGE).astype(int)\n",
    "\n",
    "    # The moving window every 26 weeks\n",
    "    df_prob_all = pd.DataFrame()\n",
    "    all_end_dates = ['2015-07-01', '2016-01-01', '2016-07-01', '2017-01-01', \n",
    "                     '2017-07-01', '2018-01-01', '2018-07-01', '2019-01-01', \n",
    "                     '2019-07-01', '2020-01-01', '2020-07-01', '2021-01-01',\n",
    "                     '2021-07-01']\n",
    "    for end_date in tqdm(all_end_dates):\n",
    "\n",
    "        end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "        start_date = next_friday(end_date - relativedelta(years=training_window))\n",
    "\n",
    "        df_output = best_pred.loc[start_date:end_date]\n",
    "\n",
    "        start_date_test = next_friday(end_date - relativedelta(months=6))\n",
    "        split_index = df_output.index.get_loc(start_date_test, method='bfill')\n",
    "        index_test = df_output.iloc[split_index:].index\n",
    "\n",
    "        features_std = pd.DataFrame(index=df_output.index, \n",
    "                                    data=PowerTransformer(method='yeo-johnson', standardize=True).fit_transform(features.reindex(df_output.index)), \n",
    "                                    columns=features.columns)\n",
    "\n",
    "        if model_name == 'MLP':\n",
    "\n",
    "            df_input = features_std.reindex(df_output.index)\n",
    "\n",
    "            df_input_train = df_input.iloc[:split_index]\n",
    "            df_output_train = df_output.iloc[:split_index]\n",
    "            df_input_test = df_input.iloc[split_index:]\n",
    "            df_output_test = df_output.iloc[split_index:]\n",
    "\n",
    "            forward_weekly_returns_train = forward_weekly_returns.reindex(df_output_train.index)\n",
    "            index_train = list(df_output_train.reset_index()[forward_weekly_returns_train.reset_index().abs_diff > threshold_return_diff].index)\n",
    "            X_train = df_input_train.values[index_train]\n",
    "            X_test = df_input_test.values\n",
    "\n",
    "        else:\n",
    "\n",
    "            df_input = features_std.loc[:end_date]\n",
    "\n",
    "            df_output_train = df_output.iloc[:split_index]\n",
    "            df_output_test = df_output.iloc[split_index:]\n",
    "\n",
    "            forward_weekly_returns_train = forward_weekly_returns.reindex(df_output_train.index)\n",
    "            index_train = list(df_output_train.reset_index()[forward_weekly_returns_train.reset_index().abs_diff > threshold_return_diff].index)\n",
    "            X = []\n",
    "            for idx in df_output.index:\n",
    "                df_input_period = df_input.loc[:idx].iloc[-input_period:]\n",
    "                X_period = df_input_period.values.reshape(input_period, nbr_features)\n",
    "                X.append(X_period)\n",
    "            X = np.array(X)\n",
    "            X_train = X[:split_index]\n",
    "            X_train = X_train[index_train]\n",
    "            X_test = X[split_index:]\n",
    "        y_train = df_output_train.values[index_train]\n",
    "        y_test = df_output_test.values\n",
    "\n",
    "        # Transform Numpy arrays to Torch tensors\n",
    "        X_train, y_train, X_test, y_test = torch.from_numpy(X_train).float(), torch.from_numpy(y_train).float(), torch.from_numpy(X_test).float(), torch.from_numpy(y_test).float()\n",
    "\n",
    "        if model_name == 'MLP':\n",
    "            model = MLP(nbr_features, num_layers=num_layers, hidden_size=hidden_size, pdrop=dropout)\n",
    "            \n",
    "        elif model_name == 'GRU':\n",
    "            model = GRU(nbr_features, hidden_size)\n",
    "\n",
    "        elif model_name == 'LSTM':\n",
    "            model = LSTM(nbr_features, hidden_size)\n",
    "\n",
    "        # Train the model\n",
    "        train(model, X_train, y_train, nb_epochs=nb_epochs, X_test=X_test, y_test=y_test, \n",
    "                batch_size=batch_size, eta=eta, weight_decay=weight_decay, verbose=verbose)\n",
    "        # Get predictions\n",
    "        prob = test(model, X_test)\n",
    "        df_prob = pd.DataFrame(index=index_test, data=prob)\n",
    "        df_prob_all = pd.concat([df_prob_all, df_prob], axis=0)\n",
    "\n",
    "    df_prob_all = df_prob_all[~df_prob_all.index.duplicated(keep='first')]\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_prob_all.values.reshape(-1, 1))\n",
    "    signal = scaler.transform(df_prob_all.values.reshape(-1, 1)).reshape(-1)\n",
    "    return pd.DataFrame(index=df_prob_all.index, data=signal)\n",
    "\n",
    "def backtest_dl(model_name):\n",
    "    \n",
    "    bench_price, target_prices, features = get_data()\n",
    "\n",
    "    batch_size = 20\n",
    "    verbose = 0\n",
    "    training_window = 4\n",
    "\n",
    "    nb_epochs = 50\n",
    "    eta = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    dropout = 0.3\n",
    "    \n",
    "    hidden_size = 20\n",
    "    num_layers = 1\n",
    "\n",
    "    input_period = 21\n",
    "\n",
    "    forward_weekly_returns = target_prices.rolling(5).apply(lambda x: np.log(x[-1] / x[0]) / len(x)).shift(-5)\n",
    "    forward_weekly_returns['abs_diff'] = np.abs(forward_weekly_returns.SMALL_MID - forward_weekly_returns.LARGE)\n",
    "\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    df_prob = backtest_strat(features=features, forward_weekly_returns=forward_weekly_returns,\n",
    "                            model_name=model_name, nb_epochs=nb_epochs,\n",
    "                            batch_size=batch_size, verbose=verbose, \n",
    "                            training_window=training_window, input_period=input_period, dropout=dropout,\n",
    "                            eta=eta, weight_decay=weight_decay, hidden_size=hidden_size, num_layers=num_layers)\n",
    "\n",
    "    portfolio = pd.DataFrame(index=df_prob.index, columns=['SMALL_MID', 'LARGE']).fillna(0)\n",
    "    portfolio['SMALL_MID'] = (df_prob > 0.6).astype(int) - (df_prob < 0.4).astype(int)\n",
    "    portfolio['LARGE'] = - portfolio.SMALL_MID\n",
    "\n",
    "    class_type, class_count = np.unique(portfolio.values, axis=0, return_counts=True)\n",
    "    weights = class_count / sum(class_count)\n",
    "\n",
    "    benchmark_portfolio = pd.read_excel('data/spiex_spi20_weights.xlsx', index_col=0)\n",
    "    benchmark_portfolio = benchmark_portfolio.rename(columns={'SPIEX':'SMALL_MID', 'SPI20': 'LARGE'})\n",
    "    benchmark_portfolio = benchmark_portfolio[['SMALL_MID', 'LARGE']]\n",
    "    benchmark_portfolio = benchmark_portfolio.reindex(portfolio.index, method='bfill')\n",
    "\n",
    "    portfolio = portfolio * 0.15 + benchmark_portfolio\n",
    "    \n",
    "    return portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_strat_sklearn(features, forward_weekly_returns, training_window, model_name):\n",
    "\n",
    "    threshold_return_diff = 0.0005\n",
    "\n",
    "    nbr_features = len(features.columns)\n",
    "\n",
    "    best_pred = (forward_weekly_returns.SMALL_MID > forward_weekly_returns.LARGE).astype(int)\n",
    "\n",
    "    # The moving window every 26 weeks\n",
    "    df_prob_all = pd.DataFrame()\n",
    "    all_end_dates = ['2015-07-01', '2016-01-01', '2016-07-01', '2017-01-01', \n",
    "                     '2017-07-01', '2018-01-01', '2018-07-01', '2019-01-01', \n",
    "                     '2019-07-01', '2020-01-01', '2020-07-01', '2021-01-01',\n",
    "                     '2021-07-01']\n",
    "    for end_date in tqdm(all_end_dates):\n",
    "\n",
    "        end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "        start_date = next_friday(end_date - relativedelta(years=training_window))\n",
    "\n",
    "        df_output = best_pred.loc[start_date:end_date]\n",
    "\n",
    "        start_date_test = next_friday(end_date - relativedelta(months=6))\n",
    "        split_index = df_output.index.get_loc(start_date_test, method='bfill')\n",
    "        index_test = df_output.iloc[split_index:].index\n",
    "\n",
    "        features_std = pd.DataFrame(index=df_output.index, \n",
    "                                    data=PowerTransformer(method='yeo-johnson', standardize=True).fit_transform(features.reindex(df_output.index)), \n",
    "                                    columns=features.columns)\n",
    "\n",
    "\n",
    "        df_input = features_std.reindex(df_output.index)\n",
    "\n",
    "        df_input_train = df_input.iloc[:split_index]\n",
    "        df_output_train = df_output.iloc[:split_index]\n",
    "        df_input_test = df_input.iloc[split_index:]\n",
    "        df_output_test = df_output.iloc[split_index:]\n",
    "\n",
    "        forward_weekly_returns_train = forward_weekly_returns.reindex(df_output_train.index)\n",
    "        index_train = list(df_output_train.reset_index()[forward_weekly_returns_train.reset_index().abs_diff > threshold_return_diff].index)\n",
    "        X_train = df_input_train.values[index_train]\n",
    "        X_test = df_input_test.values\n",
    "\n",
    "        y_train = df_output_train.values[index_train]\n",
    "        y_test = df_output_test.values\n",
    "\n",
    "        # Transform Numpy arrays to Torch tensors\n",
    "        X_train, y_train, X_test, y_test = torch.from_numpy(X_train).float(), torch.from_numpy(y_train).float(), torch.from_numpy(X_test).float(), torch.from_numpy(y_test).float()\n",
    "\n",
    "        if model_name == 'RF':\n",
    "            model = RandomForestClassifier(n_estimators=500, max_depth=20, min_samples_leaf=1, \n",
    "                                           min_samples_split=20, random_state=1)\n",
    "        elif model_name == 'logreg':\n",
    "            model = LogisticRegression(penalty='l2', class_weight='balanced')\n",
    "        \n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        prob = model.predict_proba(X_test)[:, 1]\n",
    "        df_prob = pd.DataFrame(index=index_test, data=prob)\n",
    "        df_prob_all = pd.concat([df_prob_all, df_prob], axis=0)\n",
    "\n",
    "    df_prob_all = df_prob_all[~df_prob_all.index.duplicated(keep='first')]\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_prob_all.values.reshape(-1, 1))\n",
    "    signal = scaler.transform(df_prob_all.values.reshape(-1, 1)).reshape(-1)\n",
    "    return pd.DataFrame(index=df_prob_all.index, data=signal)\n",
    "\n",
    "\n",
    "def backtest_sklearn(model_name):\n",
    "    \n",
    "    bench_price, target_prices, features = get_data()\n",
    "\n",
    "    training_window = 4\n",
    "\n",
    "    forward_weekly_returns = target_prices.rolling(5).apply(lambda x: np.log(x[-1] / x[0]) / len(x)).shift(-5)\n",
    "    forward_weekly_returns['abs_diff'] = np.abs(forward_weekly_returns.SMALL_MID - forward_weekly_returns.LARGE)\n",
    "\n",
    "    df_prob = backtest_strat_sklearn(features=features, forward_weekly_returns=forward_weekly_returns,\n",
    "                            model_name=model_name, training_window=training_window)\n",
    "\n",
    "    portfolio = pd.DataFrame(index=df_prob.index, columns=['SMALL_MID', 'LARGE']).fillna(0)\n",
    "    portfolio['SMALL_MID'] = (df_prob > 0.6).astype(int) - (df_prob < 0.4).astype(int)\n",
    "    portfolio['LARGE'] = - portfolio.SMALL_MID\n",
    "\n",
    "    class_type, class_count = np.unique(portfolio.values, axis=0, return_counts=True)\n",
    "    weights = class_count / sum(class_count)\n",
    "\n",
    "    benchmark_portfolio = pd.read_excel('data/spiex_spi20_weights.xlsx', index_col=0)\n",
    "    benchmark_portfolio = benchmark_portfolio.rename(columns={'SPIEX':'SMALL_MID', 'SPI20': 'LARGE'})\n",
    "    benchmark_portfolio = benchmark_portfolio[['SMALL_MID', 'LARGE']]\n",
    "    benchmark_portfolio = benchmark_portfolio.reindex(portfolio.index, method='bfill')\n",
    "\n",
    "    portfolio = portfolio * 0.15 + benchmark_portfolio\n",
    "\n",
    "    return portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting model MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:13<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "portfolio_mlp = backtest_dl('MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 16.73it/s]\n"
     ]
    }
   ],
   "source": [
    "portfolio_logreg = backtest_sklearn('logreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:14<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "portfolio_RF = backtest_sklearn('RF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_price, target_prices, features = get_data()\n",
    "daily_returns = target_prices.pct_change()\n",
    "perf_bench = (bench_price.reindex(portfolio_mlp.index).pct_change().fillna(0) + 1).cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_to_perf(portfolio, daily_returns):\n",
    "    first_date = portfolio.index[0]\n",
    "    last_date = portfolio.index[-1]\n",
    "    daily_ret = daily_returns.loc[first_date:last_date]\n",
    "    df_pred_daily = portfolio.reindex(daily_ret.index, method='ffill').shift(1)\n",
    "    df_daily_perf = (df_pred_daily * daily_ret).sum(axis=1)\n",
    "    cumul_perf = (1 + df_daily_perf).cumprod()\n",
    "    return cumul_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5), sharex=True, sharey=True)\n",
    "\n",
    "# LogReg\n",
    "perf_pred = pred_to_perf(portfolio_logreg, daily_returns)\n",
    "annual_returns_bench = perf_bench.resample('Y').apply(lambda x: (x[-1] - x[0]) / x[0])\n",
    "annual_returns_pred = perf_pred.resample('Y').apply(lambda x: (x[-1] - x[0]) / x[0])\n",
    "annual_diff = (annual_returns_pred - annual_returns_bench) * 100\n",
    "df_annual_diff = pd.DataFrame(columns=['year', 'alpha'])\n",
    "df_annual_diff['year'] = annual_diff.index.year\n",
    "df_annual_diff['year'] = df_annual_diff.year.apply(str)\n",
    "df_annual_diff['alpha'] = annual_diff.values\n",
    "df_annual_diff['sign'] = np.sign(df_annual_diff.alpha)\n",
    "\n",
    "sns.barplot(ax=axs[0], data=df_annual_diff, x='year', y='alpha', hue='sign', dodge=False)\n",
    "axs[0].get_legend().remove()\n",
    "axs[0].set_ylabel('Alpha (%)')\n",
    "axs[0].set_xlabel('Year')\n",
    "axs[0].set_title('Logistic Regression')\n",
    "\n",
    "# RF\n",
    "perf_pred = pred_to_perf(portfolio_RF, daily_returns)\n",
    "annual_returns_bench = perf_bench.resample('Y').apply(lambda x: (x[-1] - x[0]) / x[0])\n",
    "annual_returns_pred = perf_pred.resample('Y').apply(lambda x: (x[-1] - x[0]) / x[0])\n",
    "annual_diff = (annual_returns_pred - annual_returns_bench) * 100\n",
    "df_annual_diff = pd.DataFrame(columns=['year', 'alpha'])\n",
    "df_annual_diff['year'] = annual_diff.index.year\n",
    "df_annual_diff['year'] = df_annual_diff.year.apply(str)\n",
    "df_annual_diff['alpha'] = annual_diff.values\n",
    "df_annual_diff['sign'] = np.sign(df_annual_diff.alpha)\n",
    "\n",
    "sns.barplot(ax=axs[1], data=df_annual_diff, x='year', y='alpha', hue='sign', dodge=False)\n",
    "axs[1].get_legend().remove()\n",
    "axs[1].set_ylabel(None)\n",
    "axs[1].set_xlabel('Year')\n",
    "axs[1].tick_params(axis='y', length=0)\n",
    "axs[1].set_title('Random Forest')\n",
    "\n",
    "# MLP\n",
    "perf_pred = pred_to_perf(portfolio_mlp, daily_returns)\n",
    "annual_returns_bench = perf_bench.resample('Y').apply(lambda x: (x[-1] - x[0]) / x[0])\n",
    "annual_returns_pred = perf_pred.resample('Y').apply(lambda x: (x[-1] - x[0]) / x[0])\n",
    "annual_diff = (annual_returns_pred - annual_returns_bench) * 100\n",
    "df_annual_diff = pd.DataFrame(columns=['year', 'alpha'])\n",
    "df_annual_diff['year'] = annual_diff.index.year\n",
    "df_annual_diff['year'] = df_annual_diff.year.apply(str)\n",
    "df_annual_diff['alpha'] = annual_diff.values\n",
    "df_annual_diff['sign'] = np.sign(df_annual_diff.alpha)\n",
    "\n",
    "sns.barplot(ax=axs[2], data=df_annual_diff, x='year', y='alpha', hue='sign', dodge=False)\n",
    "axs[2].get_legend().remove()\n",
    "axs[2].set_ylabel(None)\n",
    "axs[2].tick_params(axis='y', length=0)\n",
    "axs[2].set_xlabel('Year')\n",
    "axs[2].set_title('Multi Layer Perceptron')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.05)\n",
    "plt.savefig('plots/latex/excess_returns.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
